{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os, argparse, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.polynomial import Polynomial\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse as parse_to_datetime\n",
    "import imageio\n",
    "import openpyxl\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                   Unnamed: 1  \\\n",
      "$ 3/11/22                                                                       \n",
      "File                             data\\Model Files\\HaggRes_InletStreams_WQ.csv   \n",
      "Sheet Name                                                                NaN   \n",
      "Skip Rows                                                                 NaN   \n",
      "Variable Column Name                                            Lab Parameter   \n",
      "Variable Name                                                     Temperature   \n",
      "Variable Units                                                        Celsius   \n",
      "Result Column Name                                                Result_as#2   \n",
      "Depth Column Name                                                     Depth_m   \n",
      "NA Values                                                                -999   \n",
      "Legend Label                                                         Observed   \n",
      "Date Column                                                              JDAY   \n",
      "Julian Start Day                                          2013-01-01 00:00:00   \n",
      "Figure Name *Do we need this ?*                                    Prof_plot    \n",
      "Figure Title                               Profile of Hagg Lake Segment 29 on   \n",
      "X Label                                                       Temperature, C    \n",
      "X Axis (min, max)                                                           0   \n",
      "Y Label                                                              Depth, m   \n",
      "Y Axis (min, max)                                                           0   \n",
      "Mode                                                     Prof plot 1 variable   \n",
      "Profile Plots Folder                                  plots\\modelprofileplots   \n",
      "Statistic Output Folder                                                 stats   \n",
      "\n",
      "                                                   Unnamed: 2  \n",
      "$ 3/11/22                                                      \n",
      "File                             data\\Model Files\\spr_wb1.csv  \n",
      "Sheet Name                                                NaN  \n",
      "Skip Rows                                                 NaN  \n",
      "Variable Column Name                              Constituent  \n",
      "Variable Name                                     Temperature  \n",
      "Variable Units                                        Celsius  \n",
      "Result Column Name                                    Seg_29   \n",
      "Depth Column Name                                       Depth  \n",
      "NA Values                                                 -99  \n",
      "Legend Label                                          Modeled  \n",
      "Date Column                                        Julian_day  \n",
      "Julian Start Day                                          NaN  \n",
      "Figure Name *Do we need this ?*                           NaN  \n",
      "Figure Title                                              NaN  \n",
      "X Label                                                   NaN  \n",
      "X Axis (min, max)                                          25  \n",
      "Y Label                                                   NaN  \n",
      "Y Axis (min, max)                                          35  \n",
      "Mode                                                      NaN  \n",
      "Profile Plots Folder                                      NaN  \n",
      "Statistic Output Folder                                   NaN  \n"
     ]
    }
   ],
   "source": [
    "######################## PROFILE PLOT ####################################   \n",
    "## User Input from excel config file\n",
    "\n",
    "#reading in user input from excel config excel file\n",
    "config_path = \"makeprofileplot_config.xlsx\" #Location of excel user file\n",
    "config = pd.read_excel(config_path, skiprows=2, engine='openpyxl', usecols='A:C', index_col=0, nrows=22) # Need to download openpyxl package to import xlsx\n",
    "print(config)\n",
    "\n",
    "############################################################\n",
    "\n",
    "##\n",
    "# Raise Exception indicating problem with configuration sheet\n",
    "## \n",
    "\n",
    "if len(config.columns) == 0:\n",
    "    raise Exception(\"No Data found in configuration sheet \")\n",
    "\n",
    "############################################################\n",
    "\n",
    "\n",
    "skiprows = config.at['Skip Rows', config.columns[0]]\n",
    "x_label = config.at['X Label', config.columns[0]]\n",
    "x_min = config.at['X Axis (min, max)', config.columns[0]]\n",
    "x_max = config.at['X Axis (min, max)', config.columns[1]]\n",
    "y_label = config.at['Y Label', config.columns[0]]\n",
    "y_min = config.at['Y Axis (min, max)', config.columns[0]]\n",
    "y_max = config.at['Y Axis (min, max)', config.columns[1]]\n",
    "start_day = config.at['Julian Start Day', config.columns[0]]\n",
    "obsdatapath = config.at['File', config.columns[0]]\n",
    "obs_day_column_name = config.at['Date Column', config.columns[0]]\n",
    "obs_variable = config.at['Variable Name', config.columns[0]]\n",
    "obs_variable_units = config.at['Variable Units', config.columns[0]]\n",
    "obs_variable_column_name = config.at['Variable Column Name', config.columns[0]]\n",
    "obs_depth_column_name = config.at['Depth Column Name', config.columns[0]] \n",
    "obs_result_column_name = config.at['Result Column Name', config.columns[0]]\n",
    "obs_na_values = config.at['NA Values', config.columns[0]]\n",
    "figure_title = config.at['Figure Title', config.columns[0]]\n",
    "# NOTE: append \"_column_name\" to variables that store labels (names of columns)\n",
    "modpath = config.at['File', config.columns[1]]\n",
    "mod_day_column_name = config.at['Date Column', config.columns[1]]\n",
    "mod_variable = config.at['Variable Name', config.columns[1]]\n",
    "mod_variable_column_name = config.at['Variable Column Name', config.columns[1]]\n",
    "mod_depth_column_name = config.at['Depth Column Name', config.columns[1]] \n",
    "mod_result_column_name = config.at['Result Column Name', config.columns[1]]\n",
    "mod_na_values = config.at['NA Values', config.columns[1]]\n",
    "mod_variable_units = config.at['Variable Units', config.columns[1]]\n",
    "\n",
    "profileplotfolder = config.at['Profile Plots Folder', config.columns[0]] \n",
    "statsfolder = config.at['Statistic Output Folder', config.columns[0]]\n",
    "#print(obsdatapath, obs_day, obs_param, modpath, mod_day, mod_param, profileplotfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# Config Problems - Check data and throw exceptions if missing\n",
    "# #\n",
    "\n",
    "# Note: I did not include sheet name nor skip rows, as they are currently empty\n",
    "\n",
    "def isNaN(variable):\n",
    "    '''\n",
    "        Checks for NaN values. If the variable is not equal to itself, it is a NaN type.\n",
    "        Args: variable: Variable to check for NaN\n",
    "        Return: True/False\n",
    "    '''\n",
    "    return variable!= variable\n",
    "\n",
    "# Check two of the following configurations exist (will be NaN if missing)\n",
    "for index in range(0, 2):\n",
    "    if isNaN(config.at['File', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'File' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Variable Column Name', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Variable Column Name' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Variable Name', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Variable Name' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Variable Units', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Variable Units' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Result Column Name', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Result Column Name' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Depth Column Name', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Depth Column Name' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['NA Values', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'NA Values row' in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Legend Label', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Legend Label' in in configuration sheet (expected two values).\")\n",
    "\n",
    "    if isNaN(config.at['Date Column', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Date Column' in in configuration sheet (expected two values).\")\n",
    "\n",
    "    if isNaN(config.at['X Axis (min, max)', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'X Axis (min, max)' in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Y Axis (min, max)', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Y Axis (min, max)' in in configuration sheet (expected two values).\")\n",
    "    \n",
    "# Check one of the following configurations exist (will be NaN if missing)\n",
    "for index in range(0, 1):\n",
    "    if isNaN(config.at['Julian Start Day', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Julian Start Day' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    # Uncomment to add\n",
    "    #if isNaN(config.at['Figure Name', config.columns[index]]):\n",
    "    #    raise Exception(\"Missing entry in 'Figure Name' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Figure Title', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Figure Title' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['X Label', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'X Label' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Y Label', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Y Label' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Mode', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Mode' row in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Profile Plots Folder', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Profile Plots Folder' in in configuration sheet (expected two values).\")\n",
    "    \n",
    "    if isNaN(config.at['Statistic Output Folder', config.columns[index]]):\n",
    "        raise Exception(\"Missing entry in 'Statistic Output Folder' in in configuration sheet (expected two values).\")\n",
    "    \n",
    "##\n",
    "# Trim all whitespace off of data inputs that are strings (not numbers or dates)\n",
    "## \n",
    "\n",
    "input_list = [\n",
    "    x_label,\n",
    "    y_label,\n",
    "    obsdatapath,\n",
    "    obs_day_column_name,\n",
    "    obs_variable,\n",
    "    obs_variable_units,\n",
    "    obs_variable_column_name,\n",
    "    obs_depth_column_name,\n",
    "    obs_result_column_name,\n",
    "    figure_title,\n",
    "    modpath,\n",
    "    mod_day_column_name,\n",
    "    mod_variable,\n",
    "    mod_variable_column_name,\n",
    "    mod_depth_column_name,\n",
    "    mod_result_column_name,\n",
    "    mod_variable_units,\n",
    "    profileplotfolder,\n",
    "    statsfolder\n",
    "]\n",
    "\n",
    "for parameter in input_list:\n",
    "    if not isNaN(parameter):\n",
    "        parameter = parameter.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# Linux Compatibility - Directory Handler\n",
    "# #\n",
    "\n",
    "'''\n",
    "    Windows and Linux environments use different formats for directories. This section of code\n",
    "    takes existing paths and if in a linux environment, changes '\\' to '/'. Then, it checks if those\n",
    "    directories exist in the current folder, and if not, creates them.\n",
    "\n",
    "'''\n",
    "\n",
    "import platform\n",
    "import os\n",
    "\n",
    "# If not Windows, add working directory path to variable and change '\\'\n",
    "if platform.system() != 'Windows':\n",
    "    modpath = os.getcwd() + '/' + modpath.replace('\\\\', '/') \n",
    "    obsdatapath = os.getcwd() + '/' + obsdatapath.replace('\\\\', '/') \n",
    "    profileplotfolder = os.getcwd() + '/' + profileplotfolder.replace('\\\\', '/')\n",
    "    statsfolder = os.getcwd() + '/' + statsfolder.replace('\\\\', '/')\n",
    "\n",
    "# For consiser code, added path lists to a List/Array to go through in a for loop\n",
    "path_list = [modpath, obsdatapath, profileplotfolder, statsfolder]\n",
    "\n",
    "# If directories for paths dont exist, create them\n",
    "if platform.system() != 'Windows':\n",
    "    dir_split = '/'\n",
    "    for variable in path_list:\n",
    "        build_path = ''\n",
    "        print(os.getcwd() + dir_split)\n",
    "        print(variable.split(os.getcwd() + dir_split))\n",
    "        path = variable.split(os.getcwd() + dir_split)[1].split(dir_split) # split path into array\n",
    "        if '.' in path[-1]:\n",
    "            path.pop() # Remove filename from end (Note: only works if file extension exists on end of filename)\n",
    "        for directory in path:\n",
    "            build_path += directory + dir_split\n",
    "            if not os.path.isdir(build_path):\n",
    "                os.mkdir(build_path)\n",
    "else:\n",
    "    dir_split = '\\\\'\n",
    "    for variable in path_list:\n",
    "        build_path = ''\n",
    "        path = variable.split(dir_split) # split path into array\n",
    "        if '.' in path[-1]:\n",
    "            path.pop() # Remove filename from end (Note: only works if file extension exists on end of filename)\n",
    "        for directory in path:\n",
    "            build_path += directory + dir_split\n",
    "            if not os.path.isdir(build_path):\n",
    "                os.mkdir(build_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Check Data Files for misformatted data. This will treat pandas warnings as exceptions, catching if there are mixed types in a column (like letters in a data column)\n",
    "## \n",
    "\n",
    "# NOTE: This will only flag mixed types, if the entire column is made of letters, this will not flag\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model \"data\\Model Files\\spr_wb1.csv\"\n",
      "loading observed \"data\\Model Files\\HaggRes_InletStreams_WQ.csv\"\n"
     ]
    },
    {
     "ename": "DtypeWarning",
     "evalue": "Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDtypeWarning\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mf:\\Ben\\Documents\\Side_projects\\capstone team\\CE-QUAL-W2-Data-Visualization\\CEQUALW2_04_30.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Ben/Documents/Side_projects/capstone%20team/CE-QUAL-W2-Data-Visualization/CEQUALW2_04_30.ipynb#ch0000003?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloading observed \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m obsdatapath)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Ben/Documents/Side_projects/capstone%20team/CE-QUAL-W2-Data-Visualization/CEQUALW2_04_30.ipynb#ch0000003?line=11'>12</a>\u001b[0m \u001b[39m#read in profile model outputs\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Ben/Documents/Side_projects/capstone%20team/CE-QUAL-W2-Data-Visualization/CEQUALW2_04_30.ipynb#ch0000003?line=12'>13</a>\u001b[0m moddata \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(modpath, na_values\u001b[39m=\u001b[39;49mmod_na_values)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Ben/Documents/Side_projects/capstone%20team/CE-QUAL-W2-Data-Visualization/CEQUALW2_04_30.ipynb#ch0000003?line=14'>15</a>\u001b[0m \u001b[39m#observed data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Ben/Documents/Side_projects/capstone%20team/CE-QUAL-W2-Data-Visualization/CEQUALW2_04_30.ipynb#ch0000003?line=15'>16</a>\u001b[0m obsdata \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(obsdatapath, na_values\u001b[39m=\u001b[39m obs_na_values)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=579'>580</a>\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=580'>581</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1251'>1252</a>\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1252'>1253</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1253'>1254</a>\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[0;32m   <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1254'>1255</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1255'>1256</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:227\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=224'>225</a>\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=225'>226</a>\u001b[0m     \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=226'>227</a>\u001b[0m     data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=228'>229</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=229'>230</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:404\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[1;34m(chunks)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=396'>397</a>\u001b[0m     warning_names \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(warning_columns)\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=397'>398</a>\u001b[0m     warning_message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=398'>399</a>\u001b[0m         [\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=399'>400</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumns (\u001b[39m\u001b[39m{\u001b[39;00mwarning_names\u001b[39m}\u001b[39;00m\u001b[39m) have mixed types. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=400'>401</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSpecify dtype option on import or set low_memory=False.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=401'>402</a>\u001b[0m         ]\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=402'>403</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=403'>404</a>\u001b[0m     warnings\u001b[39m.\u001b[39;49mwarn(warning_message, DtypeWarning, stacklevel\u001b[39m=\u001b[39;49mfind_stack_level())\n\u001b[0;32m    <a href='file:///c%3A/Users/Ben/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=404'>405</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mDtypeWarning\u001b[0m: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False."
     ]
    }
   ],
   "source": [
    "# loading in model and observed data\n",
    "\n",
    "print('loading model \"%s\"' % modpath)\n",
    "print('loading observed \"%s\"' % obsdatapath)\n",
    "\n",
    "#read in profile model outputs\n",
    "moddata = pd.read_csv(modpath, na_values=mod_na_values)\n",
    "\n",
    "#observed data\n",
    "obsdata = pd.read_csv(obsdatapath, na_values= obs_na_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditional Statements - Create tables for observed and modeled data\n",
    "#### This requires data to be in a specific format ####\n",
    "#Create model data table, round down days\n",
    "profobs = obsdata[(obsdata['Site'] == 'V - Hagg Lake')].copy() # conditions data to only include Site V, makes a copy so we dont alter obs data\n",
    "profobs = profobs[(profobs[obs_variable_column_name] == obs_variable)]\n",
    "profobs = profobs[[obs_day_column_name, obs_depth_column_name, obs_result_column_name]] #making a table with day, depth, and results\n",
    "profobs[obs_day_column_name] = profobs[obs_day_column_name].apply(np.floor) #round down\n",
    "profobs = profobs.dropna()\n",
    "\n",
    "#Create observed data table, round down days\n",
    "profmod = moddata[(moddata[mod_variable_column_name] == mod_variable)].copy() \n",
    "profmod = profmod[[mod_day_column_name, mod_depth_column_name, mod_result_column_name]]\n",
    "profmod[mod_day_column_name] = profmod[mod_day_column_name].apply(np.floor)\n",
    "profmod = profmod.dropna()\n",
    "\n",
    "#use this if you want to see the data\n",
    "#print('Observed data:')\n",
    "#print(profobs)\n",
    "#print('Model data:')\n",
    "#print(profmod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model days and observed days into a se\n",
    "modeldays = set(profmod[mod_day_column_name])\n",
    "observeddays = set(profobs[obs_day_column_name])\n",
    "days =  modeldays.intersection(observeddays) #find the ones that are in both data sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Index of Days in Model Dataset - In the future we may need to check that observed and modeled days match earlier in code\n",
    "#mod_ind = profmod_complete[mod_day].unique() # prof mod complete not defined\n",
    "#mod_ind #Index of Julian Days for model dataset. We are assuming the model days match the observed days.\n",
    "\n",
    "# renaming variables so they specify that they are interpolated!\n",
    "interpolated_df_day_column_name = mod_day_column_name\n",
    "interpolated_df_depth_column_name = 'Depth' #mod_depth_column_name\n",
    "interpolated_df_mod_result_column_name = mod_result_column_name\n",
    "interpolated_df_obs_result_column_name = obs_result_column_name\n",
    "interpolated_columns = [\n",
    "    interpolated_df_day_column_name, \n",
    "    interpolated_df_depth_column_name, \n",
    "    interpolated_df_mod_result_column_name, \n",
    "    interpolated_df_obs_result_column_name,\n",
    "]\n",
    "\n",
    "\n",
    "interpolated_df = pd.DataFrame(columns=interpolated_columns) #creating an empty data frame to put all of the interpolated values in\n",
    "\n",
    "#Interpolate - each days values are interpolated using this loop\n",
    "\n",
    "for i in days: # changed this to modeldays instead of mod_ind\n",
    "    profmod_i = profmod[(profmod[mod_day_column_name] == i)]\n",
    "    profobs_i = profobs[(profobs[obs_day_column_name] == i)]\n",
    "    \n",
    "    mod_depths = profmod_i[mod_depth_column_name]\n",
    "    mod_results = profmod_i[mod_result_column_name]\n",
    "    \n",
    "    obs_depths = profobs_i[obs_depth_column_name]\n",
    "    obs_results = profobs_i[obs_result_column_name]\n",
    "\n",
    "    # if there are no observed depths for day \"i\" np.interp will crash below. \n",
    "    # so, if there are none, skip this day (via \"continue\")\n",
    "    # if len(obs_depths) == 0:\n",
    "    #     print('no observed depths for day {}'.format(i))\n",
    "    #     continue\n",
    "    \n",
    "    interp_mod_results = list(np.interp(obs_depths, mod_depths, mod_results))\n",
    "    interp_mod_days = [i] * len(obs_depths)\n",
    "    interpolated_df = pd.concat([\n",
    "        interpolated_df, \n",
    "        pd.DataFrame(zip(interp_mod_days, obs_depths, interp_mod_results, obs_results), columns=interpolated_columns)\n",
    "    ])\n",
    "\n",
    "# new data frame will have day, depth, interpolated model data, observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Caluclate Statistic Values\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "stats_columns = [\n",
    "    'DAY',\n",
    "    'MAE', \n",
    "    'RMSE', \n",
    "    'ME',\n",
    "    'MODEL ST.DEV',\n",
    "    'PBIAS',\n",
    "    'MOD_MEAN',\n",
    "    'OBS_MEAN',\n",
    "]\n",
    "def make_empty_statsdf():\n",
    "    return pd.DataFrame(columns=stats_columns)\n",
    "\n",
    "def concat_statsdf(statsdf, df, day):\n",
    "    y_true = df[interpolated_df_obs_result_column_name].to_numpy()\n",
    "    y_pred = df[interpolated_df_mod_result_column_name].to_numpy()\n",
    "    MOD_MEAN = y_pred.mean()\n",
    "    OBS_MEAN = y_true.mean()\n",
    "    RMSE = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    ME = np.sum(y_pred - y_true) / len(y_true)\n",
    "    MAE = np.sum(np.absolute(y_pred - y_true))/ len(y_true)\n",
    "    MOD_ST_DEV = y_pred.std()\n",
    "    PBIAS = 100 * np.sum(y_true - y_pred) / np.sum(y_true)\n",
    "    return pd.concat([\n",
    "        statsdf,\n",
    "        pd.DataFrame([[day, MAE, RMSE, ME,MOD_ST_DEV, PBIAS, MOD_MEAN, OBS_MEAN]], columns=stats_columns)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the interpolated_df we created above\n",
    "#creating the profile plots\n",
    "\n",
    "statsdf = make_empty_statsdf()\n",
    "\n",
    "for i in days:\n",
    "    interp_i = interpolated_df[(interpolated_df[interpolated_df_day_column_name] == i)]\n",
    "    mod_i = profmod[(profmod[mod_day_column_name]==i)]\n",
    "    depths = list(interp_i[interpolated_df_depth_column_name])\n",
    "    mod_depths = list(mod_i[mod_depth_column_name])\n",
    "    x_mod = list(mod_i[mod_result_column_name])\n",
    "    x_obs = list(interp_i[interpolated_df_obs_result_column_name])\n",
    "    date = (start_day) + timedelta(days=(i-1))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_mod, mod_depths, marker = '', linestyle ='-', label = 'Model')\n",
    "    ax.plot(x_obs, depths, marker ='*', linestyle = 'None', color ='g', label = 'Observed')\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    ##\n",
    "    # Replace plt with specific figure/axis\n",
    "    ##\n",
    "\n",
    "    # plt.title(f\"{figure_title} {date.strftime('%B %d %Y')}\" )\n",
    "    # plt.xlabel(x_label)\n",
    "    # plt.ylabel(y_label)\n",
    "    # plt.legend(loc = 'lower right')\n",
    "\n",
    "    fig.suptitle(f\"{figure_title} {date.strftime('%B %d %Y')}\" )\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend(loc = 'lower right')\n",
    "    ############################################################\n",
    "\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "    ax.invert_yaxis()\n",
    "    ax.axis([x_min, x_max, y_max, y_min])\n",
    "    ax.text( 1, 2 , f\"Julian Day: {i}\")\n",
    "    plotname = f'profmod_{i}.jpg'\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    ##\n",
    "    # Catch .jpg error and retry as .png\n",
    "    ##\n",
    "\n",
    "    #fig.savefig(os.path.join(profileplotfolder, plotname))\n",
    "    \n",
    "    # Attempt to save as a .jpg, else save as a .png\n",
    "    try:\n",
    "        fig.savefig(os.path.join(profileplotfolder, plotname))\n",
    "    except ValueError:\n",
    "        print('ERROR: Unable to save as .jpg, saving as .png instead')\n",
    "        plotname = plotname.split('.')\n",
    "        plotname.pop()\n",
    "        plotname.append('png') # Throw away the file extension\n",
    "        plotname = '.'.join(plotname)\n",
    "        fig.savefig(os.path.join(profileplotfolder, plotname), format='png')\n",
    "    except:\n",
    "        print(f'Error: Unable to save {plotname}')\n",
    "    ############################################################\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    ##\n",
    "    # Fix runtime error for 20+ open plots\n",
    "    ##\n",
    "\n",
    "    #fig.clf()\n",
    "    plt.close()\n",
    "    ############################################################\n",
    "\n",
    "    statsdf = concat_statsdf(statsdf, interp_i, i).sort_values('DAY') # calling the statistics function in this loop to calculate for everyday\n",
    "\n",
    "    \n",
    "statsdf = concat_statsdf(statsdf, interpolated_df, 'AVG') #average statistics values\n",
    "statsdf.to_csv(os.path.join(statsfolder, 'Statistics.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gif of profile plots (Cui Yong, 2020)\n",
    "from pathlib import Path\n",
    "\n",
    "############################################################\n",
    "\n",
    "##\n",
    "# Function for parsing day out of file names to later assist with sorting\n",
    "##\n",
    "\n",
    "import re\n",
    "\n",
    "def numericalSort(raw):\n",
    "    ''' \n",
    "        Takes a string, splits out the numbers, converts to an int, and returns results for sorting\n",
    "        [Source: https://stackoverflow.com/questions/12093940/reading-files-in-a-particular-order-in-python]\n",
    "        Args:\n",
    "            value (string): value to be split\n",
    "        Return:\n",
    "            parts (List): string parts, seperated on number\n",
    "    '''\n",
    "    value = str(raw)\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    if len(parts) > 3:\n",
    "        return parts[3]\n",
    "    else:\n",
    "        return float('inf')  # Non-standard naming scheme - place file at end of gif\n",
    "\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')  # Regex for seperating numbers from strings\n",
    "############################################################\n",
    "\n",
    "image_path = Path(profileplotfolder)\n",
    "\n",
    "############################################################\n",
    "\n",
    "##\n",
    "# Read in files and sort them according to day. If no .jpg files exist, look for .png files\n",
    "##\n",
    "\n",
    "# images = list(image_path.glob('*.jpg'))\n",
    "\n",
    "images = []\n",
    "\n",
    "for file in sorted(list(image_path.glob('*.jpg')), key=numericalSort):\n",
    "    images.append(file)\n",
    "\n",
    "if len(images) == 0:\n",
    "    for file in sorted(list(image_path.glob('*.png')), key=numericalSort):\n",
    "        images.append(file)\n",
    "############################################################\n",
    "\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "\n",
    "len(image_list)\n",
    "imageio.mimwrite(os.path.join(profileplotfolder, 'profileplots.gif'), image_list , fps =4)\n",
    "file_name"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f3039d1060f2f153e3d4133c413038b2334374b6dabe07b03397746de413d29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
